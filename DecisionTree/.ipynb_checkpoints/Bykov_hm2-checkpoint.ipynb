{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 1 ноября 2018, 06:00 \n",
    "**Штраф за опоздание:** -2 балла после 06:00 1 ноября, -4 балла после 06:00 8 ноября, -6 баллов после 06:00 15 ноября\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw2.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (4 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. В комментариях, где написано \"Что делает этот блок кода?\", ответьте на этот вопрос. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (2 балла)\n",
    "Добиться скорости работы fit такой, чтобы она была медленнее sklearn не более чем в 10 раз. Скорость проверяем на  wine и Speed Dating Data. Для ускорения используем только numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 3 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/dmitry/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from functools import reduce\n",
    "from scipy.stats import randint as randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import GridSearchCV\n",
    "    from sklearn.cross_validation import RandomizedSearchCV\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "RND_SEED = 123\n",
    "   \n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=0.95, criterion='gini', max_features=\"sqrt\"):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "            self.impFunc = self.__ginimp\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "            self.impFunc = self.__entimp\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "            self.impFunc = self.__misimp\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __ginimp(self, y):\n",
    "        cnt = Counter(y)\n",
    "        m = np.array([cnt[i] for i in list(cnt)])\n",
    "        return 1 - np.sum(m**2 / y.shape[0]**2)\n",
    "\n",
    "    def __entimp(self, y):\n",
    "        cnt = Counter(y)\n",
    "        m = np.array([cnt[i] for i in list(cnt)])\n",
    "        return np.sum((m / y.shape[0]) * np.log2(m / y.shape[0])) * (-1)\n",
    "\n",
    "    def __misimp(self, y):\n",
    "        cnt = Counter(y)\n",
    "        m = np.array([cnt[i] for i in list(cnt)])\n",
    "        return 1 - np.max(m / y.shape[0])\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        # Ваш код в 1 строчку\n",
    "        return (1 - ((np.array((l_c / l_s) ** 2).sum(axis=1)) *\n",
    "                     ((l_s / (l_s + r_s)).T) +\n",
    "                     (np.array((r_c / r_s) ** 2).sum(axis=1)) *\n",
    "                     ((r_s / (l_s + r_s)).T)).T)\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        # Ваш код в 1 строчку\n",
    "        return ((-np.array((l_c / l_s) * np.log(l_c / l_s)).sum(axis=1)) -\n",
    "                (np.array(((r_c / r_s) * np.log(r_c / r_s))).sum(axis=1)))\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        # Ваш код в 1 строчку\n",
    "        return 1 - (l_c / l_s + r_c / r_s).max(axis=1)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        # Ваш код в 1 строчку\n",
    "        return feature_ids[range(max(1, int(math.sqrt(n_feature))))]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        # Ваш код в 1 строчку\n",
    "        return feature_ids[range(max(1, int(math.log2(n_feature))))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(max(1, int(n_feature)))  # Ваш код в 1 строчку\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода? сортирует x и y по вохврастанию x\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = self.num_class\n",
    "        cut_size = np.int(self.min_samples_split / 2 - 1)\n",
    "        #\n",
    "        # Что делает этот блок кода?\n",
    "        # обрезает части разбиений которые заведомо не нужно делить\n",
    "        # в случае если все обЪекты одного класса\n",
    "        # возращает что нигде не нужно делить\n",
    "        if cut_size == 0:\n",
    "            splitted_sorted_y = sorted_y\n",
    "        else:\n",
    "            splitted_sorted_y = sorted_y[cut_size:-cut_size]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] !=\n",
    "                                splitted_sorted_y[1:])[0] + (cut_size + 1)\n",
    "\n",
    "        if len(r_border_ids) == 0:\n",
    "            return np.inf, None\n",
    "        # Что делает этот блок кода?\n",
    "        # делает one hot coding для y и размеры разбиений\n",
    "        eq_el_count = r_border_ids - np.append(np.array([cut_size]),\n",
    "                                               r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]),\n",
    "                     sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + \\\n",
    "            np.bincount(sorted_y[:cut_size], minlength=class_number)\n",
    "        #\n",
    "        # Что делает этот блок кода? считает сколько объектов\n",
    "        # какого класса будут в поддеревьях\n",
    "        # для различных разбиений и размеры этих поддеревеьев\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(sorted_y,\n",
    "                                    minlength=class_number) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода? вызывает функции impurity\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "        #\n",
    "        # Что делает этот блок кода?\n",
    "        # возвращает значние impurity по разбиениям и лучшее разделение\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        #\n",
    "        # Ваш код\n",
    "        # Необходимо использовать следующее:\n",
    "        # self.LEAF_TYPE\n",
    "        # self.NON_LEAF_TYPE\n",
    "\n",
    "        # self.tree\n",
    "        # self.max_depth\n",
    "        # self.sufficient_share\n",
    "        # self.min_samples_split\n",
    "\n",
    "        # self.get_feature_ids\n",
    "        # self.__find_threshold\n",
    "        # self.__div_samples\n",
    "        # self.__fit_node\n",
    "        node = []\n",
    "        if((not(depth is None) and depth == self.max_depth) or\n",
    "           y.shape[0] <= self.min_samples_split or\n",
    "           (Counter(y).most_common(1)[0][1] / y.shape[0])\n",
    "           >= self.sufficient_share):\n",
    "            node.append(self.__class__.LEAF_TYPE)\n",
    "            if(y.shape[0] > 0):\n",
    "                node.append(Counter(y).most_common(1)[0][0])\n",
    "            self.tree[node_id] = (node)\n",
    "            return self.impFunc(y)\n",
    "        node.append(self.__class__.NON_LEAF_TYPE)\n",
    "        feat = self.get_feature_ids(x.shape[1])\n",
    "        f = np.array(list(map(lambda i:\n",
    "                              list(self.__find_threshold(x[:, i], y)), feat)))\n",
    "        feat_threshold = f\n",
    "        best = np.argmin(feat_threshold[:][0])\n",
    "        node.append(feat[best])\n",
    "        node.append(feat_threshold[best][1])\n",
    "        self.tree[node_id] = (node)\n",
    "        xl, xr, yl, yr = self.__div_samples(x, y, node[1], node[2])\n",
    "        if(yl.shape[0] > 0 and yr.shape[0] > 0):\n",
    "            li = self.__fit_node(xl, yl, 2*node_id+1, depth+1)\n",
    "            ri = self.__fit_node(xr, yr, 2*node_id+2, depth+1)\n",
    "            t = self.impFunc(y)*(y.shape[0]) - li*(yl.shape[0])\n",
    "            self.feature_importances_[feat[best]] += t - ri * (yr.shape[0])\n",
    "        else:\n",
    "            node = []\n",
    "            node.append(self.__class__.LEAF_TYPE)\n",
    "            if(y.shape[0] > 0):\n",
    "                node.append(Counter(y).most_common(1)[0][0])\n",
    "            self.tree[node_id] = (node)\n",
    "        return self.impFunc(y)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        fi = self.feature_importances_\n",
    "        self.feature_importances_ = fi / np.sum(fi)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        sum = 0\n",
    "        for i in range(y.shape[0]):\n",
    "            sum += pred[i] == y[i]\n",
    "        return sum / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion='entropy', max_features=\"log2\")\n",
    "clf = DecisionTreeClassifier(min_samples_split=2, criterion='entropy', max_features=\"log2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ms, sys: 261 µs, total: 3.26 ms\n",
      "Wall time: 2.26 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 ms, sys: 102 µs, total: 21.4 ms\n",
      "Wall time: 20.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: RuntimeWarning: divide by zero encountered in log\n",
      "/home/dmitry/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/dmitry/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: divide by zero encountered in log\n",
      "/home/dmitry/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857142857142858"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407407407407408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/speed-dating-experiment/Speed Dating Data.csv', encoding='latin1')\n",
    "choseddf = df[['match','gender' ,'age_o', 'race_o','goal','race_o', 'round' ,'condtn',  'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha','dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "              'amb_o', 'shar_o',  'prob_o','met_o']].dropna()\n",
    "y = np.array(choseddf['match']).astype('int')\n",
    "X=np.array(choseddf[['gender' ,'age_o', 'race_o','goal','race_o', 'round' ,'condtn',  'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha','dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "              'amb_o', 'shar_o',  'prob_o','met_o']]).astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)#, stratify=df1)\n",
    "# тут делаете то же самое, что и на семинаре https://github.com/stroykova/spheremailru/blob/master/2018-02/lecture_04_trees/pract-speed-dating-trees-proc.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion='gini', max_features=\"sqrt\")\n",
    "clf = DecisionTreeClassifier(min_samples_split=2,criterion='gini', max_features=\"sqrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951807228915663"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)\n",
    "#f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')# тут должен быть код типа f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8147590361445783"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.score(X_test, y_test)\n",
    "#f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')# тут должен быть код типа f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 ms, sys: 374 µs, total: 12.6 ms\n",
      "Wall time: 11.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)# тут должен быть код типа %time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97.1 ms, sys: 0 ns, total: 97.1 ms\n",
      "Wall time: 96.3 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)# тут должен быть код типа %time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  9  1 15 16 19 20 21 18 14]\n",
      "[17 18  2  1  7  4 12 15 21 14]\n"
     ]
    }
   ],
   "source": [
    "print(np.argsort(clf.feature_importances_)[-10:])\n",
    "print(np.argsort(my_clf.feature_importances_)[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 8}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': range(1, 10),\n",
    "    'max_depth': range(1, 50)\n",
    "}\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
